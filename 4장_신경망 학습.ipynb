{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>『 밑바닥부터 시작하는 딥러닝 』</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://image.kyobobook.co.kr/images/book/large/636/l9788968484636.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4장. 신경망 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#데이터에서-학습한다!\" data-toc-modified-id=\"데이터에서-학습한다!-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>데이터에서 학습한다!</a></span><ul class=\"toc-item\"><li><span><a href=\"#데이터-주도-학습\" data-toc-modified-id=\"데이터-주도-학습-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>데이터 주도 학습</a></span></li><li><span><a href=\"#훈련-데이터와-시험-데이터\" data-toc-modified-id=\"훈련-데이터와-시험-데이터-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>훈련 데이터와 시험 데이터</a></span></li></ul></li><li><span><a href=\"#손실-함수\" data-toc-modified-id=\"손실-함수-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>손실 함수</a></span><ul class=\"toc-item\"><li><span><a href=\"#오차제곱합-(SSE)\" data-toc-modified-id=\"오차제곱합-(SSE)-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>오차제곱합 (SSE)</a></span></li><li><span><a href=\"#교차-엔트로피-오차-(CEE)\" data-toc-modified-id=\"교차-엔트로피-오차-(CEE)-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>교차 엔트로피 오차 (CEE)</a></span></li><li><span><a href=\"#미니배치-학습\" data-toc-modified-id=\"미니배치-학습-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>미니배치 학습</a></span></li><li><span><a href=\"#(배치용)-교차-엔트로피-오차-구현하기\" data-toc-modified-id=\"(배치용)-교차-엔트로피-오차-구현하기-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>(배치용) 교차 엔트로피 오차 구현하기</a></span></li><li><span><a href=\"#왜-손실-함수를-설정하는가?\" data-toc-modified-id=\"왜-손실-함수를-설정하는가?-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>왜 손실 함수를 설정하는가?</a></span></li></ul></li><li><span><a href=\"#수치-미분\" data-toc-modified-id=\"수치-미분-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>수치 미분</a></span><ul class=\"toc-item\"><li><span><a href=\"#미분\" data-toc-modified-id=\"미분-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>미분</a></span></li><li><span><a href=\"#수치-미분의-예\" data-toc-modified-id=\"수치-미분의-예-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>수치 미분의 예</a></span></li><li><span><a href=\"#편미분\" data-toc-modified-id=\"편미분-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>편미분</a></span></li></ul></li><li><span><a href=\"#기울기\" data-toc-modified-id=\"기울기-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>기울기</a></span><ul class=\"toc-item\"><li><span><a href=\"#경사법(경사-하강법)\" data-toc-modified-id=\"경사법(경사-하강법)-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>경사법(경사 하강법)</a></span></li><li><span><a href=\"#신경망에서의-기울기\" data-toc-modified-id=\"신경망에서의-기울기-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>신경망에서의 기울기</a></span></li></ul></li><li><span><a href=\"#학습-알고리즘-구현하기\" data-toc-modified-id=\"학습-알고리즘-구현하기-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>학습 알고리즘 구현하기</a></span><ul class=\"toc-item\"><li><span><a href=\"#신경망-학습-절차-복습\" data-toc-modified-id=\"신경망-학습-절차-복습-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>신경망 학습 절차 복습</a></span></li><li><span><a href=\"#2층-신경망-클래스-구현하기\" data-toc-modified-id=\"2층-신경망-클래스-구현하기-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>2층 신경망 클래스 구현하기</a></span></li><li><span><a href=\"#미니배치-학습-구현하기\" data-toc-modified-id=\"미니배치-학습-구현하기-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>미니배치 학습 구현하기</a></span></li><li><span><a href=\"#시험-데이터로-평가하기\" data-toc-modified-id=\"시험-데이터로-평가하기-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>시험 데이터로 평가하기</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 장의 주제는 **신경망 학습**입니다. 여기서 학습이란 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것입니다. 신경망이 학습할 수 있도록 해주는 지표인 **손실 함수**의 결괏값을 가장 작게 만드는 가중치 매개변수를 찾는 것이 학습의 목표입니다. 손실 함수의 값을 가급적 작게 만드는 기법으로, **함수의 기울기를 활용하는 경사법**을 소개합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터에서 학습한다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망의 특징은 데이터를 보고 학습할 수 있다는 점입니다. 가중치 매개변수 값을 데이터를 보고 자동으로 결정한다는 뜻입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 주도 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망과 딥러닝은 기존 기계학습에서 사용하던 방법보다 사람의 개입을 더욱 배재할 수 있게 해주는 중요한 특성을 찾습니다. **특징(feature)**이란 입력 데이터에서 본질적인 데이터를 정확하게 추출할 수 있도록 설계된 변환기를 가리킵니다.  \n",
    "\n",
    "**기계 학습**에서는 모아진 데이터로부터 규칙을 찾아내는 역할은 '기계'가 담당하지만, 이미지를 벡터로 변환할 때 사용하는 특징은 '사람'이 설계합니다. 이 말은 적합한 특징을 쓰지 않으면 좋은 결과를 얻지 못한다는 말입니다. 반면 **신경망(딥러닝)** 방식은 사람이 개입하지 않습니다. 그리하여 딥러닝은 **종단간 기계학습(end-to-end mechine learning)**이라고도 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.vlpt.us/images/jakeseo_me/post/d9bacee1-a872-4bd2-adcc-2ce3510397b1/fig%204-2.png\" width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 데이터와 시험 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기계학습 문제는 데이터를 **훈련 데이터(training data)**와 **시험 데이터(test data)**로 나눠 학습과 실험을 수행하는 것이 일반적입니다. 우선 훈련 데이터만 사용하여 학습하면서 최적의 매개변수를 찾습니다. 그런 다음 시험 데이터를 사용하여 앞서 훈련한 모델의 실력을 평가하는 것입니다.  \n",
    "\n",
    "그래서 데이터셋 하나로만 매개변수의 학습과 평가를 수행하면 올바른 평가가 될 수 없습니다. 수중의 데이터셋은 제대로 맞히더라도 다른 데이터셋에는 엉망인 일도 벌어집니다. **한 데이터셋에만 지나치게 최적화된 상태**를 **오버피팅(overfitting)**이라고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 학습에서는 형재의 상태를 하나의 지표인 **손실 함수**로 표현하고, 이를 가장 좋게 만들어주는 가중치 매개변수의 값을 탐색합니다. '행복 지표'를 가진 사람이 그 지표를 근거로 '최적의 인생'을 탐색하듯, 신경망도 '손실 함수'를 기준으로 '최적의 매개변수 값'을 탐색합니다.  \n",
    "\n",
    "이때, 손실 함수는 신경망 성능의 '나쁨'을 나타내는 지표입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오차제곱합 (SSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 많이 쓰이는 손실 합수는 **오차제곱합(sum of squares for error, SSE)**입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.vlpt.us/images/jakeseo_me/post/1f308ef9-a787-44b2-b7d1-31753e849591/MSE.png\" width=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 **y_k**는 **신경망의 출력(신경망이 추정한 값)**, **t_k**는 **정답 레이블**, **k**는 **데이터의 차원 수**를 나타냅니다.  \n",
    "\n",
    "이때, 1/2는 미분을 쉽게 하기 위해 존재합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:56.304308Z",
     "start_time": "2021-01-27T06:56:56.004113Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:56.313285Z",
     "start_time": "2021-01-27T06:56:56.307303Z"
    }
   },
   "outputs": [],
   "source": [
    "def sum_squares_error(y, t):\n",
    "    return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:56.334228Z",
     "start_time": "2021-01-27T06:56:56.318275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 로 예측한 경우: 0.09750000000000003, \n",
      "7 로 예측한 경우: 0.5975\n"
     ]
    }
   ],
   "source": [
    "# 정답은 2\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# 예1: '2'일 확률이 가장 높다고 추정함(0.6)\n",
    "y = [0.1, 0.05, 0.6, 0, 0.05, 0.1, 0, 0.1, 0, 0]\n",
    "ex_1 = sum_squares_error(np.array(y), np.array(t))\n",
    "\n",
    "# 예2: '7'일 확률이 가장 높다고 추정함(0.6)\n",
    "y = [0.1, 0.05, 0.1, 0, 0.05, 0.1, 0, 0.6, 0, 0]\n",
    "ex_2 = sum_squares_error(np.array(y), np.array(t))\n",
    "\n",
    "print('2 로 예측한 경우: {}, \\n7 로 예측한 경우: {}'.format(ex_1, ex_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 예제 결과를 봤을 때, 오차제곱합 기준으로는 첫 번째 추정 결과가 오차가 더 작으므로 정답에 더 가까울 것으로 판단할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 엔트로피 오차 (CEE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또 다른 손실 함수로서 **교차 엔트로피 오차(cross entropy error, CEE)**도 자주 이용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.vlpt.us/images/jakeseo_me/post/0e182974-46dc-42bd-bd74-146f7dd7737f/CEE.png\" width=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에서 log는 밑이 e인 자연로그(log_e)입니다. **y_k**는 **신경망의 출력**, **t_k**는 **정답 레이블**입니다.  \n",
    "이때 t_k는 정답에 해당하는 인덱스의 원소만 1이고 나머지는 0인 원-핫 인코딩 형태이기 때문에 실질적으로 정답일 때의 추정(t_k가 1일 때의 y_k)의 자연로그를 계산하는 식이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:56.343206Z",
     "start_time": "2021-01-27T06:56:56.337223Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    # np.log() 함수에 0을 입력하면 마이너스 무한대를 뜻하는 -inf가 되어 \n",
    "    # 더 이상 계산을 진행할 수 없게 되기 때문에 아주 작은 값을 더해서 0이 되지 않도록 함\n",
    "    delta = 1e-7  \n",
    "    return -np.sum(t * np.log(y + delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:56.356171Z",
     "start_time": "2021-01-27T06:56:56.346198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 로 예측한 경우: 0.510825457099338, \n",
      "7 로 예측한 경우: 2.302584092994546\n"
     ]
    }
   ],
   "source": [
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# 예1: '2'일 확률이 가장 높다고 추정함(0.6)\n",
    "y = [0.1, 0.05, 0.6, 0, 0.05, 0.1, 0, 0.1, 0, 0]\n",
    "ex_1 = cross_entropy_error(np.array(y), np.array(t))\n",
    "\n",
    "# 예2: '7'일 확률이 가장 높다고 추정함(0.6)\n",
    "y = [0.1, 0.05, 0.1, 0, 0.05, 0.1, 0, 0.6, 0, 0]\n",
    "ex_2 = cross_entropy_error(np.array(y), np.array(t))\n",
    "\n",
    "print('2 로 예측한 경우: {}, \\n7 로 예측한 경우: {}'.format(ex_1, ex_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉, 결과(오차 값)가 더 작은 첫 번째 추정이 정답일 가능성이 높다고 판단한 것으로, 앞서 오차제곱합의 판단과 일치합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미니배치 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지는 데이터 하나에 대한 손실 합수만 생각해왔습니다. 이제부터는 훈련 데이터 모두에 대한 손실 함수의 합을 구하는 방법을 생각해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.vlpt.us/images/jakeseo_me/post/2019fce0-df94-434d-9a26-7d793f5b0917/batch_CEE.png\" width=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 N개인 경우이고, **t_nk**는 **n번째 데이터의 k번째 값**을 의미합니다. 마지막에 N으로 나누어 정규화하고 있습니다. N으로 나눔으로써 '평균 손실 함수'를 구하는 것입니다.  \n",
    "\n",
    "그런데 훈련 데이터의 개수가 너무 많아진다면 일일이 손실 함수를 계산하는 것은 현실적이지 않습니다. 이런 경우 데이터 일부를 추려 전체의 근사치로 이용합니다. **훈련 데이터로부터 일부만 골라 학습을 수행**하며, 이 **일부**를 **미니배치(mini-batch)**라고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (배치용) 교차 엔트로피 오차 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:56.369138Z",
     "start_time": "2021-01-27T06:56:56.359164Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.rasahep(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 왜 손실 함수를 설정하는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "왜 **정확도**라는 지표를 놔두고 **손실 함수**라는 값이라는 우회적인 방법을 택하는 이유가 무엇일까요? 이 의문은 신경망 학습에서의 **미분**의 역할에 주목한다면 해결됩니다.  \n",
    "\n",
    "신경망 학습에서는 손실 함수의 값을 가장 작게 하는 매개변수 값을 찾습니다. 이때 매개변수의 미분(정확히는 기울기)를 계산하고, 그 미분 값을 단서로 매개변수의 값을 서서히 갱신하는 과정을 반복합니다.  \n",
    "가중치 **매개변수의 손실 함수의 미분**이란 **가중치 매개변수의 값을 아주 조금 변화시켰을 때, 손실 함수가 어떻게 변하나**라는 의미입니다. 미분 값이 0이 될 때 가중치 매개변수의 갱신이 멈춥니다.  \n",
    "\n",
    "정확도를 지표로 삼아서는 안 되는 이유는 미분 값이 대부분의 장소에서 0이 되어 매개변수를 갱신할 수 없기 때문입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.vlpt.us/images/jakeseo_me/post/08a50cb6-a1f9-4498-adeb-2bd46ec3ae23/fig%204-4.png\" width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도를 계단 함수에, 손실 함수를 시그모이드 함수에 비유할 수 있습니다. 계단 함수는 한순간만 변화를 일으키지만, 시그모이드 함수는 출력이 연속적으로 변하고 곡선의 기울기도 변합니다. 즉, 시그모이드 함수의 미분은 어느 장소라도 0이 되지는 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수치 미분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "경사법에서는 기울기(경사) 값을 기준으로 나아갈 방향을 정합니다. 기울기란 무엇인지, 또 어떤 성질이 있는지를 설명하기에 앞서, 이번 절에서는 **미분**부터 복습해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미분은 특정 순간의 변화량을 뜻합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.vlpt.us/images/jakeseo_me/post/d9d74dd0-107c-445f-bc7b-d4fa8349a96e/meboon.png\" width=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉, x의 작은 변화가 함수 f(x)를 얼마나 변화시키느냐를 의미합니다. 이때 시간의 작은 변화, 즉 시간을 뜻하는 h를 한없이 0에 가깝게 한다는 의미를 lim으로 나타납니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:56.380107Z",
     "start_time": "2021-01-27T06:56:56.372128Z"
    }
   },
   "outputs": [],
   "source": [
    "# 나쁜 구현 예\n",
    "def numerical_diff(f, x):\n",
    "    h = 1e-50\n",
    "    return (f(x+h) - f(x)) / (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 구현은 작은 값이 생략되어 최종 계산 결과에 오차가 생기는 **반올림 오차(rounding error)** 문제를 일으킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:56.404043Z",
     "start_time": "2021-01-27T06:56:56.385095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.float32(1e-50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또한 진정한 미분이 아니라 함수 f의 차분을 계산하는 한계가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.vlpt.us/images/jakeseo_me/post/98fba7d4-7d0c-451a-9df1-09c0a367b5e7/fig%204-5.png\" width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리하여 다음과 같이 중심 차분(중앙 차분)을 통해 구현하기도 합니다. 다음은 나쁜 구현에서의 두 개선점을 적용해 다시 구현한 수치 미분입니다.  \n",
    "\n",
    "(수치 미분이란 아주 작은 차분으로 미분하는 것을 말합니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:56.416011Z",
     "start_time": "2021-01-27T06:56:56.408034Z"
    }
   },
   "outputs": [],
   "source": [
    "def numerical_diff(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    return (f(x+h) - f(x-h)) / (2*h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수치 미분의 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:56.983383Z",
     "start_time": "2021-01-27T06:56:56.419004Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:56.990364Z",
     "start_time": "2021-01-27T06:56:56.986386Z"
    }
   },
   "outputs": [],
   "source": [
    "def function_1(x):\n",
    "    return 0.01*x**2 + 0.1*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.278756Z",
     "start_time": "2021-01-27T06:56:56.993959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0.0, 20.0, 0.1)\n",
    "y = function_1(x)\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.289726Z",
     "start_time": "2021-01-27T06:56:57.281748Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1999999999990898, 0.2999999999986347)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_1, 5), numerical_diff(function_1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 편미분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**편미분**이란 변수가 여럿인 함수에 대한 미분을 말합니다. 편미분은 앞의 예와 달리 변수가 2개라는 점에 주의해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.300696Z",
     "start_time": "2021-01-27T06:56:57.292719Z"
    }
   },
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기울기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 변수의 편미분을 벡터로 정리한 것을 **기울기(gradient)**라고 합니다. 기울기는 다음과 같이 구현할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.327625Z",
     "start_time": "2021-01-27T06:56:57.303688Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.341604Z",
     "start_time": "2021-01-27T06:56:57.330617Z"
    }
   },
   "outputs": [],
   "source": [
    "def _numerical_gradient_no_batch(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x) # x와 형상이 같은 배열을 생성\n",
    "    \n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        \n",
    "        # f(x+h) 계산\n",
    "        x[idx] = float(tmp_val) + h\n",
    "        fxh1 = f(x)\n",
    "        \n",
    "        # f(x-h) 계산\n",
    "        x[idx] = tmp_val - h \n",
    "        fxh2 = f(x) \n",
    "        \n",
    "        grad[idx] = (fxh1 - fxh2) / (2*h)\n",
    "        x[idx] = tmp_val # 값 복원\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.356548Z",
     "start_time": "2021-01-27T06:56:57.345580Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 8.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_numerical_gradient_no_batch(function_2, np.array([3.0, 4.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기울기는 각 지점에서 낮아지는 방향을 가리킵니다. 더 정확히 말하자면 **기울기가 가리키는 쪽은 각 장소에서 함수의 출력 값을 가장 크게 줄이는 방향**입니다. 이건 중요한 포인트이니 확실히 기억하세요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경사법(경사 하강법)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**< 경사법이란 >**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망은 최적의 매개변수(가중치와 편향)를 학습 시에 찾아야 합니다. 여기에서 최적이란 손실 합수가 최솟값이 될 때의 매개변수 값입니다. 그러나 매개변수의 공간이 광대하여 어디가 최솟값이 되는 곳인지를 짐작할 수 없습니다. 이런 상황에서 기울기를 잘 이용해 함수의 최솟값(또는 가능한 한 작은 값)을 찾으려는 것이 **경사법**입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://image.librewiki.net/thumb/4/4f/%EA%B2%BD%EC%82%AC%ED%95%98%EA%B0%95%EB%B2%95_Local_minima.png/450px-%EA%B2%BD%EC%82%AC%ED%95%98%EA%B0%95%EB%B2%95_Local_minima.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이때, 주의할 점은 각 지점에서 함수의 값을 낮추는 방안을 제시하는 지표가 기울기라는 것입니다. 기울기가 가리키는 곳에 정말 함수의 최솟값이 있는지, 그쪽이 정말로 나아갈 방향인지는 보장할 수 없습니다.  \n",
    "\n",
    "    (경사 하강법은 국소적인 최솟값(local minima)을 찾을 수 있지만, 이것이 전역적인 최솟값(global minimum)이라는 보장은 없다!)\n",
    "\n",
    "드디어 경사법이 등장할 차례입니다. 경사법은 현 위치에서 기울어진 방향으로 일정 거리만큼 이동합니다. 그런 다음 이동한 곳에서도 마찬가지로 기울기를 구하고, 또 그 기울어진 방향으로 나아가기를 반복합니다. 이렇게 해서 함수의 값을 점차 줄이는 것이 **경사법(gradient method)**입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "경사법은 최솟값을 찾는 경우 **경사 하강법(gradient descent method)**, 최댓값을 찾는 경우 **경사 상승법(gradient ascent method)**라고 합니다. 일반적으로 신경망(딥러닝) 분야에서의 경사법은 '경사 하감법'으로 등장할 때가 많습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.vlpt.us/images/jakeseo_me/post/1d5481d5-c66d-4c92-86d7-b4c8c83c8c60/gradient_descent_method_equation.png\" width=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**< 경사 하강법에서의 학습률 >**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "경사법의 수식에서 **η(에타)**는 갱신하는 양을 나타냅니다. 이를 신경망 학습에서는 **학습률(learning rate)**이라고 합니다. 한 번의 학습으로 얼마만큼 학습해야 할지, 즉 매개변수 값을 얼마나 갱신하느냐를 정하는 것이 학습률입니다. 위에서 나타낸 수식은 1회에 해당하는 갱신이고, 이 단계를 반복합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://mblogthumb-phinf.pstatic.net/MjAyMDAzMTZfODcg/MDAxNTg0MzAxMTIzNzkx.30RyWOQ5ZR-Z2uJbeVJnHe-22HPsc6ap6tSpYJL0m1wg.dPzbux16yI1QpvQKyJztLVNGH87nIybM8A8-h5ITwHsg.PNG.jevida/031520_1938_Gradient3.png?type=w800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습률 값이 너무 크거나 작으면 좋은 장소를 찾아갈 수 없습니다. 경사 하강법은 다음과 같이 간단하게 구현할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.368516Z",
     "start_time": "2021-01-27T06:56:57.359540Z"
    }
   },
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr=0.01, step_num=100):\n",
    "    x = init_x\n",
    "    x_history = []\n",
    "\n",
    "    for i in range(step_num):\n",
    "        x_history.append( x.copy() )\n",
    "\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "\n",
    "    return x, np.array(x_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문제: 경사법으로 x_0^2 + x_1^2의 최솟값을 구하라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.379486Z",
     "start_time": "2021-01-27T06:56:57.370510Z"
    }
   },
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.392466Z",
     "start_time": "2021-01-27T06:56:57.382482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmmnj\\Desktop\\2021\\DL\\dl_from_scratch\\deep_learning_from_scratch\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\kmmnj\\Desktop\\2021\\DL\\dl_from_scratch\\deep_learning_from_scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.406415Z",
     "start_time": "2021-01-27T06:56:57.395445Z"
    }
   },
   "outputs": [],
   "source": [
    "from common.gradient import numerical_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.424365Z",
     "start_time": "2021-01-27T06:56:57.408410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.11110793e-10,  8.14814391e-10])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_x = np.array([-3.0, 4.0])    \n",
    "\n",
    "lr = 0.1\n",
    "step_num = 100\n",
    "x, x_history = gradient_descent(function_2, init_x, lr=lr, step_num=step_num)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 그래프는 경사법을 사용한 갱신 과정을 그림으로 나타낸 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.642782Z",
     "start_time": "2021-01-27T06:56:57.430350Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot( [-5, 5], [0,0], '--b')\n",
    "plt.plot( [0,0], [-5, 5], '--b')\n",
    "plt.plot(x_history[:,0], x_history[:,1], 'o')\n",
    "\n",
    "plt.xlim(-3.5, 3.5)\n",
    "plt.ylim(-4.5, 4.5)\n",
    "plt.xlabel(\"X0\")\n",
    "plt.ylabel(\"X1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습률을 훨씬 크고, 작게 설정하여 실험해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.664723Z",
     "start_time": "2021-01-27T06:56:57.649764Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.58983747e+13, -1.29524862e+12])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_x = np.array([-3.0, 4.0])    \n",
    "\n",
    "# 학습률이 너무 큰 예: lr=10.0\n",
    "lr = 10\n",
    "step_num = 100\n",
    "x, x_history = gradient_descent(function_2, init_x, lr=lr, step_num=step_num)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.681691Z",
     "start_time": "2021-01-27T06:56:57.667717Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.99999994,  3.99999992])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_x = np.array([-3.0, 4.0])    \n",
    "\n",
    "# 학습률이 너무 작은 예: 1e-10\n",
    "lr = 1e-10\n",
    "step_num = 100\n",
    "x, x_history = gradient_descent(function_2, init_x, lr=lr, step_num=step_num)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습률이 너무 크면 큰 값으로 발산해버리고, 너무 작으면 거의 갱신되지 않은 채 끝나버립니다. 이것으로 학습률을 적저리 설정하는 일의 중요성을 알아보았습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망에서의 기울기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 학습에서도 기울기를 구해야 합니다. 여기서 말하는 기울기는 **가중치 매개변수에 대한 손실 함수의 기울기**입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.690654Z",
     "start_time": "2021-01-27T06:56:57.684670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmmnj\\Desktop\\2021\\DL\\dl_from_scratch\\deep_learning_from_scratch\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\kmmnj\\Desktop\\2021\\DL\\dl_from_scratch\\deep_learning_from_scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.707609Z",
     "start_time": "2021-01-27T06:56:57.693646Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "from common.functions import softmax, cross_entropy_error\n",
    "from common.gradient import numerical_gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "간단한 신경망을 예로 들어 실제로 기울기를 구하는 코드를 구현해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.717581Z",
     "start_time": "2021-01-27T06:56:57.709605Z"
    }
   },
   "outputs": [],
   "source": [
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2,3) # 정규분포로 초기화\n",
    "\n",
    "    def predict(self, x):           # 메서드1: 예측 수행\n",
    "        return np.dot(x, self.W)\n",
    "\n",
    "    def loss(self, x, t):           # 메서드2: 손실 함수 값 계산\n",
    "        z = self.predict(x)         # x: 입력 데이터 / t: 정답 레이블\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.730546Z",
     "start_time": "2021-01-27T06:56:57.720575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.44309177  0.27644505 -0.51857611]\n",
      " [-1.34200937  0.86297397 -0.55189285]]\n"
     ]
    }
   ],
   "source": [
    "net = simpleNet()\n",
    "print(net.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.744510Z",
     "start_time": "2021-01-27T06:56:57.733539Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.47366349  0.9425436  -0.80784924]\n"
     ]
    }
   ],
   "source": [
    "# (1, 2) 내적 (2, 3) -> (1, 3)\n",
    "x = np.array([0.6, 0.9])\n",
    "p = net.predict(x)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.757475Z",
     "start_time": "2021-01-27T06:56:57.749497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(p) # 최댓값의 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.772435Z",
     "start_time": "2021-01-27T06:56:57.759472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9838544162261007"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([0, 0, 1]) # 정답 레이블\n",
    "net.loss(x, t) # 손실 함수 값 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이어서 기울기를 구해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.779419Z",
     "start_time": "2021-01-27T06:56:57.774429Z"
    }
   },
   "outputs": [],
   "source": [
    "def f(W):\n",
    "    return net.loss(x, t)\n",
    "\n",
    "# 새로운 함수를 정의할 때 lambda 기법을 쓰면 구현이 더 편함\n",
    "# f = lambda w: net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.794377Z",
     "start_time": "2021-01-27T06:56:57.785401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.04240471  0.47507212 -0.51747683]\n",
      " [ 0.06360707  0.71260818 -0.77621525]]\n"
     ]
    }
   ],
   "source": [
    "dW = numerical_gradient(f, net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 신경망의 기울기를 구한 다음에는 경사법에 따라 매개변수를 갱신하기만 하면 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 알고리즘 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**신경망 학습의 중요 키워드**\n",
    "- 손실 함수\n",
    "- 미니 배치\n",
    "- 기울기\n",
    "- 경사 하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 신경망 학습 절차 복습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- **전제**  \n",
    "신경망에는 적응 가능한 **가중치**와 **편향**이 있고, 이 가중치와 편향을 **훈련 데이터에 적응하도록 조정**하는 과정을 **학습**이라고 합니다. 신경망 학습은 다음과 같은 4단계로 수행합니다.  \n",
    "---\n",
    "- **1단계: 미니배치**  \n",
    "훈련 데이터 중 일부를 무작위로 가져옵니다. 이렇게 선별한 데이터를 **미니 배치**라 하며, 그 미니배치의 **손실 함수 값**을 줄이는 것이 목표입니다.  \n",
    "---\n",
    "- **2단계: 기울기 산출**  \n",
    "미니배치의 손실 함수 값을 줄이기 위해 **각 가중치 매개변수의 기울기**를 구합니다. 기울기는 손실 함수의 값을 가장 작게 하는 방향을 제시합니다.  \n",
    "---\n",
    "- **3단계: 매개변수 갱신**  \n",
    "가중치 매개변수를 기울기 방향으로 아주 조금 갱신합니다.  \n",
    "---\n",
    "- **4단계: 반복**  \n",
    "1~3 단계를 반복합니다.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이것이 신경망 학습이 이뤄지는 순서입니다. 이는 경사 하강법으로 매개변수를 갱신하는 방법이며, 이때 데이터를 미니배치로 무작위로 선정하기 때문에 **확률적 경사 하강법(Stochastc Gradient Descent, SGD)**이라고 부릅니다. 대부분의 딥러닝 프레임워크는 SGD라는 함수로 이 기능을 구현하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2층 신경망 클래스 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에서는 **2층 신경망(은닉층이 1개인 네트워크)**을 대상으로 MNIST 데이터셋을 사용하여 학습을 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.803352Z",
     "start_time": "2021-01-27T06:56:57.797368Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.841251Z",
     "start_time": "2021-01-27T06:56:57.807342Z"
    }
   },
   "outputs": [],
   "source": [
    "class TwoLayerNet:\n",
    "    \n",
    "    # 가중치 초기화를 수행한다.\n",
    "    # 인수는 순서대로 입력층, 은닉층, 출력층의 뉴런 수\n",
    "    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01): \n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size) # 1번째 가중치\n",
    "        self.params['b1'] = np.zeros(hidden_size) # 1번째 편향\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "    # 예측(추론)을 수행한다.\n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "    \n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    # 손실 함수의 값을 구한다.    \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        \n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    # 정확도를 구한다.\n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis=1)\n",
    "        t = np.argmax(t, axis=1)\n",
    "        \n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "        \n",
    "    # (1) 가중치 매개변수의 기울기를 구한다. \n",
    "    # x : 입력 데이터, t : 정답 레이블\n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = lambda W: self.loss(x, t)\n",
    "        \n",
    "        grads = {} \n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1']) # 1번째 가중치의 기울기\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1']) # 1번째 편향의 기울기\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "        \n",
    "        return grads\n",
    "     \n",
    "    # (2) 가중치 매개변수의 기울기를 구한다. / numerical_gradient()의 성능 개선판\n",
    "    # 오차역전파법을 사용하여 기울기를 효율적이고 빠르게 계산\n",
    "    def gradient(self, x, t):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "        grads = {}\n",
    "        \n",
    "        batch_num = x.shape[0]\n",
    "        \n",
    "        # forward\n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(z1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "        \n",
    "        # backward\n",
    "        dy = (y - t) / batch_num\n",
    "        grads['W2'] = np.dot(z1.T, dy)\n",
    "        grads['b2'] = np.sum(dy, axis=0)\n",
    "        \n",
    "        da1 = np.dot(dy, W2.T)\n",
    "        dz1 = sigmoid_grad(a1) * da1\n",
    "        grads['W1'] = np.dot(x.T, dz1)\n",
    "        grads['b1'] = np.sum(dz1, axis=0)\n",
    "\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미니배치 학습 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "처음에는 2층 신경망을 하나의 클래스로 구현하는 것부터 시작합니다. (코드를 주석으로 처리해둔 부분은 5.4에서 다루는 부분입니다.)  \n",
    "그 전에 batch size와 epoch을 다시 이해하고 넘어가도록 합시다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://mblogthumb-phinf.pstatic.net/MjAxOTAxMjNfMjU4/MDAxNTQ4MjM1Nzg3NTA2.UtvnGsckZhLHOPPOBWH841IWsZFzNcgwZvYKi2nxImEg.CdtqIxOjWeBo4eNBD2pXu5uwYGa3ZVUr8WZvtldArtYg.PNG.qbxlvnf11/20190123_182720.png?type=w800\" width=60%>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.856212Z",
     "start_time": "2021-01-27T06:56:57.844244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kmmnj\\Desktop\\2021\\DL\\dl_from_scratch\\deep_learning_from_scratch\\ch04\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\kmmnj\\Desktop\\2021\\DL\\dl_from_scratch\\deep_learning_from_scratch\\ch04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:57.882176Z",
     "start_time": "2021-01-27T06:56:57.859203Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:58.255181Z",
     "start_time": "2021-01-27T06:56:57.886132Z"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:58.264158Z",
     "start_time": "2021-01-27T06:56:58.257175Z"
    }
   },
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "iters_num = 10000  # 반복 횟수를 적절히 설정한다. (경사법에 의한 갱신 횟수)\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100   # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "# train_acc_list = []\n",
    "# test_acc_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:56:58.277122Z",
     "start_time": "2021-01-27T06:56:58.269143Z"
    }
   },
   "outputs": [],
   "source": [
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:25:15.568570Z",
     "start_time": "2021-01-27T06:25:15.562587Z"
    }
   },
   "source": [
    "학습을 시작해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:57:21.286235Z",
     "start_time": "2021-01-27T06:56:58.281112Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 소요 시간: 22.9962\n"
     ]
    }
   ],
   "source": [
    "# 1에폭당 반복 수\n",
    "# iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치(100) 획득 -> 매번 60000개의 훈련 데이터에서 100개의 데이터를 추려냄\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    \"\"\"\n",
    "    # 1에폭당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n",
    "    \"\"\"\n",
    "    \n",
    "print('총 소요 시간: {:.4f}'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "갱신할 때마다 훈련 데이터에 대한 손실 함수를 계산하고, 그 값을 배열에 추가합니다. 이 손실 함수의 값이 변화하는 추이를 그래프로 나타내면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:57:21.730455Z",
     "start_time": "2021-01-27T06:57:21.289228Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_loss_list))\n",
    "plt.plot(x, train_loss_list, label='train acc')\n",
    "# plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"iteration\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 횟수가 늘어가면서 손실 함수의 값이 줄어드는 것을 확인할 수 있습니다. 신경망의 가중치 매개변수가 서서히 데이터에 적응하고 있음을 의미합니다. 다시 말해 데이터를 반복해서 학습함으로써 최적 가중치 매개변수로 서서히 다가서고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시험 데이터로 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3에서 손실 함수의 값이 서서히 내려가는 것을 확인했습니다. 다만, 이때의 손실 함수 값이란 **훈련 데이터의 미니배치에 대한 손실 함수**의 값입니다. 이 결과만으로는 다른 새로운 데이터셋에도 비슷한 실력을 발휘할지는 확실하지 않습니다. 다른 말로, **오버피팅**을 일으키지 않는지 확인해야 합니다.  \n",
    "\n",
    "이를 위해 다음 구현에서는 학습 도중 정기적으로 훈련 데이터와 시험 데이터를 대상으로 정확도를 기록합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:57:21.740465Z",
     "start_time": "2021-01-27T06:57:21.733449Z"
    }
   },
   "outputs": [],
   "source": [
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:57:21.752624Z",
     "start_time": "2021-01-27T06:57:21.743640Z"
    }
   },
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "iters_num = 10000  # 반복 횟수를 적절히 설정한다. (경사법에 의한 갱신 횟수)\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100   # 미니배치 크기\n",
    "learning_rate = 0.1\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:57:56.914039Z",
     "start_time": "2021-01-27T06:57:21.754611Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 0.0903 | test acc: 0.0892\n",
      "train acc: 0.7756 | test acc: 0.7833\n",
      "train acc: 0.8759 | test acc: 0.8778\n",
      "train acc: 0.8984 | test acc: 0.9024\n",
      "train acc: 0.9076 | test acc: 0.9099\n",
      "train acc: 0.9131 | test acc: 0.9156\n",
      "train acc: 0.9189 | test acc: 0.9222\n",
      "train acc: 0.9229 | test acc: 0.9245\n",
      "train acc: 0.9276 | test acc: 0.9282\n",
      "train acc: 0.9307 | test acc: 0.9319\n",
      "train acc: 0.9337 | test acc: 0.9342\n",
      "train acc: 0.9365 | test acc: 0.9367\n",
      "train acc: 0.9387 | test acc: 0.9399\n",
      "train acc: 0.9413 | test acc: 0.9406\n",
      "train acc: 0.9436 | test acc: 0.9430\n",
      "train acc: 0.9441 | test acc: 0.9438\n",
      "train acc: 0.9461 | test acc: 0.9434\n",
      "총 소요 시간: 35.1475\n"
     ]
    }
   ],
   "source": [
    "# 1에폭당 반복 수\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(iters_num):\n",
    "    # 미니배치(100) 획득 -> 매번 60000개의 훈련 데이터에서 100개의 데이터를 추려냄\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "    \n",
    "    # 기울기 계산\n",
    "    #grad = network.numerical_gradient(x_batch, t_batch)\n",
    "    grad = network.gradient(x_batch, t_batch)\n",
    "    \n",
    "    # 매개변수 갱신\n",
    "    for key in ('W1', 'b1', 'W2', 'b2'):\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    # 학습 경과 기록\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "    \n",
    "    # 1에폭당 정확도 계산\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train, t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "        # print(\"train acc, test acc | \" + str(train_acc) + \", \" + str(test_acc))\n",
    "        print('train acc: {:.4f} | test acc: {:.4f}'.format(train_acc, test_acc))\n",
    "\n",
    "print('총 소요 시간: {:.4f}'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-27T06:57:57.268093Z",
     "start_time": "2021-01-27T06:57:56.917030Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(len(train_acc_list))\n",
    "plt.plot(x, train_acc_list, label='train acc')\n",
    "plt.plot(x, test_acc_list, label='test acc', linestyle='--')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프를 보면 알 수 있듯이 에폭이 진행될수록(학습이 진행될수록) 훈련 데이터와 시험 데이터를 사용하고 평가한 정확도가 모두 좋아지고 있습니다. 또, 두 정확도에는 차이가 없음을 알 수 있습니다. 다시 말해 오버피팅이 일어나지 않았습니다. (아래의 그래프가 오버피팅이 일어났을 때의 그래프입니다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://t1.daumcdn.net/cfile/tistory/99F2953D5B76CCA20B\" width=40%>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "194.533px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
