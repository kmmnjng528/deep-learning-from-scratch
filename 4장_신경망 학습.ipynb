{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>『 밑바닥부터 시작하는 딥러닝 』</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://image.kyobobook.co.kr/images/book/large/636/l9788968484636.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4장. 신경망 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#데이터에서-학습한다!\" data-toc-modified-id=\"데이터에서-학습한다!-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>데이터에서 학습한다!</a></span><ul class=\"toc-item\"><li><span><a href=\"#데이터-주도-학습\" data-toc-modified-id=\"데이터-주도-학습-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>데이터 주도 학습</a></span></li><li><span><a href=\"#훈련-데이터와-시험-데이터\" data-toc-modified-id=\"훈련-데이터와-시험-데이터-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>훈련 데이터와 시험 데이터</a></span></li></ul></li><li><span><a href=\"#손실-함수\" data-toc-modified-id=\"손실-함수-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>손실 함수</a></span><ul class=\"toc-item\"><li><span><a href=\"#오차제곱합-(SSE)\" data-toc-modified-id=\"오차제곱합-(SSE)-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>오차제곱합 (SSE)</a></span></li><li><span><a href=\"#교차-엔트로피-오차-(CEE)\" data-toc-modified-id=\"교차-엔트로피-오차-(CEE)-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>교차 엔트로피 오차 (CEE)</a></span></li><li><span><a href=\"#미니배치-학습\" data-toc-modified-id=\"미니배치-학습-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>미니배치 학습</a></span></li><li><span><a href=\"#(배치용)-교차-엔트로피-오차-구현하기\" data-toc-modified-id=\"(배치용)-교차-엔트로피-오차-구현하기-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>(배치용) 교차 엔트로피 오차 구현하기</a></span></li><li><span><a href=\"#왜-손실-함수를-설정하는가?\" data-toc-modified-id=\"왜-손실-함수를-설정하는가?-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>왜 손실 함수를 설정하는가?</a></span></li></ul></li><li><span><a href=\"#수치-미분\" data-toc-modified-id=\"수치-미분-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>수치 미분</a></span><ul class=\"toc-item\"><li><span><a href=\"#미분\" data-toc-modified-id=\"미분-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>미분</a></span></li><li><span><a href=\"#수치-미분의-예\" data-toc-modified-id=\"수치-미분의-예-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>수치 미분의 예</a></span></li><li><span><a href=\"#편미분\" data-toc-modified-id=\"편미분-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>편미분</a></span></li></ul></li><li><span><a href=\"#기울기\" data-toc-modified-id=\"기울기-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>기울기</a></span></li><li><span><a href=\"#학습-알고리즘-구현하기\" data-toc-modified-id=\"학습-알고리즘-구현하기-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>학습 알고리즘 구현하기</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 장의 주제는 **신경망 학습**입니다. 여기서 학습이란 훈련 데이터로부터 가중치 매개변수의 최적값을 자동으로 획득하는 것입니다. 신경망이 학습할 수 있도록 해주는 지표인 **손실 함수**의 결괏값을 가장 작게 만드는 가중치 매개변수를 찾는 것이 학습의 목표입니다. 손실 함수의 값을 가급적 작게 만드는 기법으로, **함수의 기울기를 활용하는 경사법**을 소개합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터에서 학습한다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망의 특징은 데이터를 보고 학습할 수 있다는 점입니다. 가중치 매개변수 값을 데이터를 보고 자동으로 결정한다는 뜻입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 주도 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망과 딥러닝은 기존 기계학습에서 사용하던 방법보다 사람의 개입을 더욱 배재할 수 있게 해주는 중요한 특성을 찾습니다. **특징(feature)**이란 입력 데이터에서 본질적인 데이터를 정확하게 추출할 수 있도록 설계된 변환기를 가리킵니다.  \n",
    "\n",
    "**기계 학습**에서는 모아진 데이터로부터 규칙을 찾아내는 역할은 '기계'가 담당하지만, 이미지를 벡터로 변환할 때 사용하는 특징은 '사람'이 설계합니다. 이 말은 적합한 특징을 쓰지 않으면 좋은 결과를 얻지 못한다는 말입니다. 반면 **신경망(딥러닝)** 방식은 사람이 개입하지 않습니다. 그리하여 딥러닝은 **종단간 기계학습(end-to-end mechine learning)**이라고도 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.vlpt.us/images/jakeseo_me/post/d9bacee1-a872-4bd2-adcc-2ce3510397b1/fig%204-2.png\" width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 데이터와 시험 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기계학습 문제는 데이터를 **훈련 데이터(training data)**와 **시험 데이터(test data)**로 나눠 학습과 실험을 수행하는 것이 일반적입니다. 우선 훈련 데이터만 사용하여 학습하면서 최적의 매개변수를 찾습니다. 그런 다음 시험 데이터를 사용하여 앞서 훈련한 모델의 실력을 평가하는 것입니다.  \n",
    "\n",
    "그래서 데이터셋 하나로만 매개변수의 학습과 평가를 수행하면 올바른 평가가 될 수 없습니다. 수중의 데이터셋은 제대로 맞히더라도 다른 데이터셋에는 엉망인 일도 벌어집니다. **한 데이터셋에만 지나치게 최적화된 상태**를 **오버피팅(overfitting)**이라고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 손실 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 학습에서는 형재의 상태를 하나의 지표인 **손실 함수**로 표현하고, 이를 가장 좋게 만들어주는 가중치 매개변수의 값을 탐색합니다. '행복 지표'를 가진 사람이 그 지표를 근거로 '최적의 인생'을 탐색하듯, 신경망도 '손실 함수'를 기준으로 '최적의 매개변수 값'을 탐색합니다.  \n",
    "\n",
    "이때, 손실 함수는 신경망 성능의 '나쁨'을 나타내는 지표입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 오차제곱합 (SSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 많이 쓰이는 손실 합수는 **오차제곱합(sum of squares for error, SSE)**입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.vlpt.us/images/jakeseo_me/post/1f308ef9-a787-44b2-b7d1-31753e849591/MSE.png\" width=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 **y_k**는 **신경망의 출력(신경망이 추정한 값)**, **t_k**는 **정답 레이블**, **k**는 **데이터의 차원 수**를 나타냅니다.  \n",
    "\n",
    "이때, 1/2는 미분을 쉽게 하기 위해 존재합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T04:03:44.216466Z",
     "start_time": "2021-01-26T04:03:41.640735Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T04:03:44.225394Z",
     "start_time": "2021-01-26T04:03:44.219410Z"
    }
   },
   "outputs": [],
   "source": [
    "def sum_squares_error(y, t):\n",
    "    return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T04:03:44.274728Z",
     "start_time": "2021-01-26T04:03:44.230381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 로 예측한 경우: 0.09750000000000003, \n",
      "7 로 예측한 경우: 0.5975\n"
     ]
    }
   ],
   "source": [
    "# 정답은 2\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# 예1: '2'일 확률이 가장 높다고 추정함(0.6)\n",
    "y = [0.1, 0.05, 0.6, 0, 0.05, 0.1, 0, 0.1, 0, 0]\n",
    "ex_1 = sum_squares_error(np.array(y), np.array(t))\n",
    "\n",
    "# 예2: '7'일 확률이 가장 높다고 추정함(0.6)\n",
    "y = [0.1, 0.05, 0.1, 0, 0.05, 0.1, 0, 0.6, 0, 0]\n",
    "ex_2 = sum_squares_error(np.array(y), np.array(t))\n",
    "\n",
    "print('2 로 예측한 경우: {}, \\n7 로 예측한 경우: {}'.format(ex_1, ex_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 예제 결과를 봤을 때, 오차제곱합 기준으로는 첫 번째 추정 결과가 오차가 더 작으므로 정답에 더 가까울 것으로 판단할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 교차 엔트로피 오차 (CEE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또 다른 손실 함수로서 **교차 엔트로피 오차(cross entropy error, CEE)**도 자주 이용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.vlpt.us/images/jakeseo_me/post/0e182974-46dc-42bd-bd74-146f7dd7737f/CEE.png\" width=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에서 log는 밑이 e인 자연로그(log_e)입니다. **y_k**는 **신경망의 출력**, **t_k**는 **정답 레이블**입니다.  \n",
    "이때 t_k는 정답에 해당하는 인덱스의 원소만 1이고 나머지는 0인 원-핫 인코딩 형태이기 때문에 실질적으로 정답일 때의 추정(t_k가 1일 때의 y_k)의 자연로그를 계산하는 식이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T04:03:44.289264Z",
     "start_time": "2021-01-26T04:03:44.281289Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    # np.log() 함수에 0을 입력하면 마이너스 무한대를 뜻하는 -inf가 되어 \n",
    "    # 더 이상 계산을 진행할 수 없게 되기 때문에 아주 작은 값을 더해서 0이 되지 않도록 함\n",
    "    delta = 1e-7  \n",
    "    return -np.sum(t * np.log(y + delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T04:03:44.374040Z",
     "start_time": "2021-01-26T04:03:44.297244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 로 예측한 경우: 0.510825457099338, \n",
      "7 로 예측한 경우: 2.302584092994546\n"
     ]
    }
   ],
   "source": [
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "# 예1: '2'일 확률이 가장 높다고 추정함(0.6)\n",
    "y = [0.1, 0.05, 0.6, 0, 0.05, 0.1, 0, 0.1, 0, 0]\n",
    "ex_1 = cross_entropy_error(np.array(y), np.array(t))\n",
    "\n",
    "# 예2: '7'일 확률이 가장 높다고 추정함(0.6)\n",
    "y = [0.1, 0.05, 0.1, 0, 0.05, 0.1, 0, 0.6, 0, 0]\n",
    "ex_2 = cross_entropy_error(np.array(y), np.array(t))\n",
    "\n",
    "print('2 로 예측한 경우: {}, \\n7 로 예측한 경우: {}'.format(ex_1, ex_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉, 결과(오차 값)가 더 작은 첫 번째 추정이 정답일 가능성이 높다고 판단한 것으로, 앞서 오차제곱합의 판단과 일치합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미니배치 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지는 데이터 하나에 대한 손실 합수만 생각해왔습니다. 이제부터는 훈련 데이터 모두에 대한 손실 함수의 합을 구하는 방법을 생각해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.vlpt.us/images/jakeseo_me/post/2019fce0-df94-434d-9a26-7d793f5b0917/batch_CEE.png\" width=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터가 N개인 경우이고, **t_nk**는 **n번째 데이터의 k번째 값**을 의미합니다. 마지막에 N으로 나누어 정규화하고 있습니다. N으로 나눔으로써 '평균 손실 함수'를 구하는 것입니다.  \n",
    "\n",
    "그런데 훈련 데이터의 개수가 너무 많아진다면 일일이 손실 함수를 계산하는 것은 현실적이지 않습니다. 이런 경우 데이터 일부를 추려 전체의 근사치로 이용합니다. **훈련 데이터로부터 일부만 골라 학습을 수행**하며, 이 **일부**를 **미니배치(mini-batch)**라고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (배치용) 교차 엔트로피 오차 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T04:03:44.450895Z",
     "start_time": "2021-01-26T04:03:44.394989Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size)\n",
    "        y = y.rasahep(1, y.size)\n",
    "        \n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 왜 손실 함수를 설정하는가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "왜 **정확도**라는 지표를 놔두고 **손실 함수**라는 값이라는 우회적인 방법을 택하는 이유가 무엇일까요? 이 의문은 신경망 학습에서의 **미분**의 역할에 주목한다면 해결됩니다.  \n",
    "\n",
    "신경망 학습에서는 손실 함수의 값을 가장 작게 하는 매개변수 값을 찾습니다. 이때 매개변수의 미분(정확히는 기울기)를 계산하고, 그 미분 값을 단서로 매개변수의 값을 서서히 갱신하는 과정을 반복합니다.  \n",
    "가중치 **매개변수의 손실 함수의 미분**이란 **가중치 매개변수의 값을 아주 조금 변화시켰을 때, 손실 함수가 어떻게 변하나**라는 의미입니다. 미분 값이 0이 될 때 가중치 매개변수의 갱신이 멈춥니다.  \n",
    "\n",
    "정확도를 지표로 삼아서는 안 되는 이유는 미분 값이 대부분의 장소에서 0이 되어 매개변수를 갱신할 수 없기 때문입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.vlpt.us/images/jakeseo_me/post/08a50cb6-a1f9-4498-adeb-2bd46ec3ae23/fig%204-4.png\" width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "정확도를 계단 함수에, 손실 함수를 시그모이드 함수에 비유할 수 있습니다. 계단 함수는 한순간만 변화를 일으키지만, 시그모이드 함수는 출력이 연속적으로 변하고 곡선의 기울기도 변합니다. 즉, 시그모이드 함수의 미분은 어느 장소라도 0이 되지는 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수치 미분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "경사법에서는 기울기(경사) 값을 기준으로 나아갈 방향을 정합니다. 기울기란 무엇인지, 또 어떤 성질이 있는지를 설명하기에 앞서, 이번 절에서는 **미분**부터 복습해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 미분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "미분은 특정 순간의 변화량을 뜻합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.vlpt.us/images/jakeseo_me/post/d9d74dd0-107c-445f-bc7b-d4fa8349a96e/meboon.png\" width=30%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉, x의 작은 변화가 함수 f(x)를 얼마나 변화시키느냐를 의미합니다. 이때 시간의 작은 변화, 즉 시간을 뜻하는 h를 한없이 0에 가깝게 한다는 의미를 lim으로 나타납니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T04:03:44.477835Z",
     "start_time": "2021-01-26T04:03:44.464858Z"
    }
   },
   "outputs": [],
   "source": [
    "# 나쁜 구현 예\n",
    "def numerical_diff(f, x):\n",
    "    h = 1e-50\n",
    "    return (f(x+h) - f(x)) / (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 구현은 작은 값이 생략되어 최종 계산 결과에 오차가 생기는 **반올림 오차(rounding error)** 문제를 일으킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T04:03:44.522785Z",
     "start_time": "2021-01-26T04:03:44.487838Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.float32(1e-50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또한 진정한 미분이 아니라 함수 f의 차분을 계산하는 한계가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.vlpt.us/images/jakeseo_me/post/98fba7d4-7d0c-451a-9df1-09c0a367b5e7/fig%204-5.png\" width=50%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리하여 다음과 같이 중심 차분(중앙 차분)을 통해 구현하기도 합니다. 다음은 나쁜 구현에서의 두 개선점을 적용해 다시 구현한 수치 미분입니다.  \n",
    "\n",
    "(수치 미분이란 아주 작은 차분으로 미분하는 것을 말합니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T04:03:44.542822Z",
     "start_time": "2021-01-26T04:03:44.531811Z"
    }
   },
   "outputs": [],
   "source": [
    "def numerical_diff(f, x):\n",
    "    h = 1e-4 # 0.0001\n",
    "    return (f(x+h) - f(x-h)) / (2*h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 수치 미분의 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T04:03:45.410896Z",
     "start_time": "2021-01-26T04:03:44.549804Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T04:03:45.418871Z",
     "start_time": "2021-01-26T04:03:45.413883Z"
    }
   },
   "outputs": [],
   "source": [
    "def function_1(x):\n",
    "    return 0.01*x**2 + 0.1*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T04:03:45.707098Z",
     "start_time": "2021-01-26T04:03:45.422859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(0.0, 20.0, 0.1)\n",
    "y = function_1(x)\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "\n",
    "plt.plot(x, y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T04:03:45.716075Z",
     "start_time": "2021-01-26T04:03:45.710091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1999999999990898, 0.2999999999986347)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_diff(function_1, 5), numerical_diff(function_1, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 편미분"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**편미분**이란 변수가 여럿인 함수에 대한 미분을 말합니다. 편미분은 앞의 예와 달리 변수가 2개라는 점에 주의해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-26T04:03:45.727046Z",
     "start_time": "2021-01-26T04:03:45.719070Z"
    }
   },
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 알고리즘 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "194.533px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
